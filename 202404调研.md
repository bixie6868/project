## Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs (CVPR 2024)
### 动机：
没有动机，专注于引入外部知识来回答问题，开发专门用于处理外部知识的架构，而不是提出一个新颖的框架或者vision-and-language adapters
**关注数据集** ： MLLM处理与外部数据相关的Query能力的评估（需要引入外部知识的评估） Infoseek 和 Encyclopedic-VQA
**号称** ： 第一个利用外部资源检索能力的MLLM
