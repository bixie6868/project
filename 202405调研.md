# 目录：
- [Question Aware Vision Transformer for Multimodal Reasoning(CVPR 2024,Amazon)](#question-aware-vision-transformer-for-multimodal-reasoningcvpr-2024amazon)
- [Small Language Models Fine-tuned to Coordinate Larger Language Models Improve Complex Reasoning（EMNLP，2023）](#small-language-models-fine-tuned-to-coordinate-larger-language-models-improve-complex-reasoningemnlp2023)
- 
# Question Aware Vision Transformer for Multimodal Reasoning(CVPR 2024,Amazon)
## 动机：
* 大部分Vision-Language模型都是由vision encoder以及LLM和对齐模块组成，但忽视了vision encoding和user queries脱钩
* 贡献： 提出QA-ViT，将question-aware嵌入到视觉编码器，重点关注于问题的相关图像方面。
  ![image](https://github.com/bixie6868/project/assets/78329110/887a5ffd-88c2-43fb-8dff-a81c3a255722)
* 总体框架：
  ![image](https://github.com/bixie6868/project/assets/78329110/3bc759c4-9add-4516-a305-898d4e8549ad)
* ![image](https://github.com/bixie6868/project/assets/78329110/45316dbe-cb9f-4467-8631-8815d5efde43)
# Small Language Models Fine-tuned to Coordinate Larger Language Models Improve Complex Reasoning（EMNLP，2023）
![image](https://github.com/bixie6868/project/assets/78329110/64e17749-d17b-448f-8eed-4012c749dadb)
# Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering（CVPR 2024，Northeastern University）
## 动机：
让模型在无法回答问题时，选择弃权。像GPT-4这种黑盒无法到模型内部去进行更改。
## 贡献：
模型在可视化问题附近的响应的一致性将表明可靠性   
![image](https://github.com/bixie6868/project/assets/78329110/84bcf5b6-a139-4b11-9b01-981891fa633d)
## 实验部分
* 训练模型VQG，可以根据V和A生成问题    
* ![image](https://github.com/bixie6868/project/assets/78329110/dcfd047e-e0f0-41c6-9360-5777cb7dd459)
* **实验结果：**
* ![image](https://github.com/bixie6868/project/assets/78329110/b5052394-e50e-4cb9-88fb-d579cfbc848a)

# How to Configure Good In-Context Sequence for Visual Question Answering（CVPR 2024，东南大学）
## 动机：
* ICL经常通过随机选择来配置上下文序列，因此导致不理想或者次优的结果
## 贡献：
* 探索多样的上下文配置，以找到最有效的配置
* 探究了不同的retrieval策略的效果
* ![image](https://github.com/bixie6868/project/assets/78329110/2c271c4f-e724-4cda-ba92-bfab5dee4e96)


