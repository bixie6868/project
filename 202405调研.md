# 目录：
- [Question Aware Vision Transformer for Multimodal Reasoning(CVPR 2024,Amazon)](#question-aware-vision-transformer-for-multimodal-reasoningcvpr-2024amazon)
- [Small Language Models Fine-tuned to Coordinate Larger Language Models Improve Complex Reasoning（EMNLP，2023）](#small-language-models-fine-tuned-to-coordinate-larger-language-models-improve-complex-reasoningemnlp2023)
# Question Aware Vision Transformer for Multimodal Reasoning(CVPR 2024,Amazon)
## 动机：
* 大部分Vision-Language模型都是由vision encoder以及LLM和对齐模块组成，但忽视了vision encoding和user queries脱钩
* 贡献： 提出QA-ViT，将question-aware嵌入到视觉编码器，重点关注于问题的相关图像方面。
  ![image](https://github.com/bixie6868/project/assets/78329110/887a5ffd-88c2-43fb-8dff-a81c3a255722)
* 总体框架：
  ![image](https://github.com/bixie6868/project/assets/78329110/3bc759c4-9add-4516-a305-898d4e8549ad)
* ![image](https://github.com/bixie6868/project/assets/78329110/45316dbe-cb9f-4467-8631-8815d5efde43)
# Small Language Models Fine-tuned to Coordinate Larger Language Models Improve Complex Reasoning（EMNLP，2023）
![image](https://github.com/bixie6868/project/assets/78329110/64e17749-d17b-448f-8eed-4012c749dadb)

